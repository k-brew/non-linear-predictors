---
title: "Project 003 - Nonlinear Predictors"
author: "Kyle Brewster"
date: "3/13/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Part 0: Prep Work
```{r message=FALSE, warning=FALSE, results='hide'}
library(pacman)
p_load(readr, dplyr, caret, tidyverse, ranger, spark, tidymodels, party, parsnip, workflows, rpart)
setwd("C:/Users/Kyle/Desktop/WINTER 22 - UO/Econometrics/aa_projects")
election_data = read_csv("election_2016.csv")
```

```{r}
election_data$i_republican_2016 = as.factor(election_data$i_republican_2016)
election_data$i_republican_2012 = as.factor(election_data$i_republican_2012)

# Adding a variable found to be significant from last time
election_data = election_data %>%
  mutate(log_inc_hh = log(income_median_hh),
         log_home_med = log(home_median_value),
         intrxt_var = (log_inc_hh*log_home_med),
         n_dem_var = (n_votes_democrat_2012/n_votes_total_2012),
         n_rep_var = (n_votes_republican_2012/n_votes_total_2012))
```

Let's remember one of the simpler models that performed better from the previous assignment
```{r}
reg_previous = glm(data = election_data, i_republican_2016 ~ 
                     intrxt_var + 
                     n_dem_var+
                     i_republican_2012,
                   family = binomial)
election_data$pred_prob<-round(fitted(reg_previous),2)
mean(election_data$pred_prob)

classificationtable<-table(election_data$i_republican_2016,
                           election_data$pred_prob > 0.5)
print(classificationtable)
```


USE RSS as test stat
# Part 1: One Tree
Converting outcome into character-class per recommendation in assignment
```{r}
p_load(parsnip, recipes, yardstick, tidyverse, rpart.plot)
election_data = election_data %>%
  mutate(i_rep_2016_ind = if_else(i_republican_2016 == 1,
                                  "Rep_Major", "Dem_Major"))

set.seed(123)

# Creating Train/Test Splits
train_election_data = election_data %>%
  sample_frac(0.8)
test_election_data = anti_join(election_data, train_election_data, by = 'fips')

# Removing 'fips' since it is an indicator value
train_election_data = train_election_data %>%
  select(-c('fips'))
test_election_data = test_election_data %>%
  select(-c('fips'))
```

```{r single tree 1}
# Planting trees
  ## Below was the default selection made by the algorithm
elect_full_trees <- rpart(formula = i_rep_2016_ind ~ .,
                       data = train_election_data,
                       method = "class",  # classification (not regression)
                       xval = 5  # 5-fold cross-validation 
                       )
rpart.plot(elect_full_trees, yesno = TRUE)
plotcp(elect_full_trees)

elect_prev_reg_trees <- rpart(formula = i_rep_2016_ind ~ 
                          intrxt_var +
                          n_dem_var+
                          i_republican_2012,
                       data = train_election_data,
                       method = "class",  # classification (not regression)
                       xval = 5  # 5-fold cross-validation 
                       )
rpart.plot(elect_prev_reg_trees, yesno = TRUE)
plotcp(elect_prev_reg_trees)
```
So far the second option is looking better. 

```{r}
test_election_data$tree_pred_values <- predict(
  elect_prev_reg_trees, test_election_data, type = "vector")

test_election_data=test_election_data %>%
  mutate(tree_pred_ind = if_else(tree_pred_values == 2,
                                  "Rep_Major", "Dem_Major"))

```

Another method (from class as opposed to the internet)
```{r}
set.seed(1234)
train2_election_data = election_data %>%
  sample_frac(0.8)
test2_election_data = anti_join(election_data, train2_election_data, by = 'fips')

# Removing 'fips' since it is an indicator value
train2_election_data = train2_election_data %>%
  select(-c('fips'))
test2_election_data = test2_election_data %>%
  select(-c('fips'))
```

```{r single tree 2}
set.seed(1234)
default_cv = train2_election_data %>% vfold_cv(v =5)
# Define the decision tree
default_tree = decision_tree(mode ="classification",
                             cost_complexity = tune(),
                             tree_depth = tune(),
                             min_n =10) %>%
  set_engine("rpart")
# Defining recipe
default_recipe = recipe(i_rep_2016_ind ~., data = train2_election_data)
# Defining workflow
default_flow = workflow() %>%
  add_model(default_tree) %>%
  add_recipe(default_recipe)
# Tuning
default_cv_fit = default_flow %>%
  tune_grid(
    default_cv,
    grid = expand_grid(
      cost_complexity = seq(0, 0.15, by = 0.01),
      tree_depth = c(1,2,5,10),
    ),
    metrics = metric_set(accuracy, roc_auc)
  )
# Fitting the best model
best_flow = default_flow %>%
  finalize_workflow(select_best(default_cv_fit, metric = "accuracy")) %>%
  fit(data = train2_election_data)
# Choosing the best model
best_tree = best_flow %>% extract_fit_parsnip()
# Plotting the tree
best_tree$fit %>% rpart.plot()
```

# Part 2: Bag o' Trees 

We can reuse some of the coding that we had done before, but with a different approach
```{r packages bago}
p_load(rpart, parsnip, yardstick)
library(baguette)
```

```{r eval=FALSE, bago trees}
# Defining recipe
p_load(party)
default_recipe_bago = recipe(i_rep_2016_ind ~., data = train_election_data) %>%
  step_medianimpute(all_predictors()&all_numeric())%>%
  step_modeimpute(all_predictors()&all_nominal())

bago_predictors <- train2_election_data %>% select(c("i_rep_2016_ind"))
bago_variables <- train2_election_data %>% select(-c("i_republican_2016",
                                                     "pred_prob",
                                                     "predictions"))

# Using caret because baguette was not working
treebag = bag(x= bago_variables,y =bago_predictors,
              bagControl = bagControl(fit = ctreeBag$fit,
                                      predict = ctreeBag$pred,
                                      aggregate = ctreeBag$aggregate),
              trControl = trainControl(method = "oob"))


# Defining our next decision tree slightly differently
default__bago = baguette::bag_tree(mode ="classification",
                             cost_complexity = 0,
                             tree_depth = NULL,
                             min_n =2,
                             class_cost = NULL) %>%
  set_engine(
    engine = "rpart",
    times = 50)
bag
# Defining workflow
default_flow_bago = workflow() %>%
  add_model(default_tree) %>%
  add_recipe(default_recipe_bago)
# Tuning
default_cv_fit_bago = default_flow %>%
  tune_grid(
    default_cv,
    grid = expand_grid(
      cost_complexity = seq(0, 0.15, by = 0.01),
      tree_depth = c(1,2,5,10),
    ),
    metrics = metric_set(accuracy, roc_auc)
  )
# Fitting the best model
best_flow_bago = default_flow_bago %>%
  finalize_workflow(select_best(default_cv_fit_bago, metric = "accuracy")) %>%
  fit(data = train2_election_data)
# Choosing the best model
best_tree_bago = best_flow_bago %>% extract_fit_parsnip()
# Plotting the tree
best_tree_bago$fit %>% rpart.plot()
```

# Part 3: Forests

```{r}
p_load(ranger, tidymodels, parsnip, randomForest, party)

# Defining parameter grid
forest_grid = expand_grid(
  mtry = 1:13,
  min_n = 1:15
)

# Writing function given hyper parameters
frst_fcnt_i = function(i) {
# Define the decision tree
woodlands_i = rand_forest(mode ="classification",
                             min_n =forest_grid$min_n[i],
                             trees = 50,
                             mtry = forest_grid$mtry[i]) %>%
  set_engine(engine = "ranger", splitrule = "gini")
# Defining workflow
forest_flow_i = workflow() %>%
  add_model(woodlands) %>%
  add_recipe(default_recipe)

# Fitting
forest_rf_fit_i = forest_flow %>%
  fit(train2_election_data)
tibble(
  mtry = forest_grid$mtry[i],
  min_n = forest_grid$min_n[i],
  error_oob = forest_rf_fit_i$fit$fit$fit$prediction.error
)
}


frst_fcnt_i()
library(parallel)
library(data.table)
# Fitting the Random Forests
forest_tunage = mclapply(
  X = 1:nrow(forest_grid),
  FUN = frst_fcnt_i) 


```

```{r message=FALSE, warning=FALSE}
library(randomForest)
train2_election_data$i_rep_2016_ind = is.factor(train2_election_data$i_rep_2016_ind)
rf = randomForest(i_rep_2016_ind ~.,data = train2_election_data)


```

```{r}
woodlands_i = rand_forest(mode ="classification",
                             min_n =forest_grid$min_n[i],
                             trees = 50,
                             mtry = forest_grid$mtry[i]) %>%
  set_engine(engine = "ranger", splitrule = "gini")
# Defining workflow
forest_flow_i = workflow() %>%
  add_model(woodlands_i) %>%
  add_recipe(default_recipe)

library(rminer)
forest_rf_fit_i = forest_flow_i %>%
  fit(i_rep_2016, data = train2_election_data, formula = i_rep_2016_ind ~., model = "randomForest") %>%
  metrics = metric_set(accuracy, roc_auc)
  
# Fitting the best model
best_rf_flow = forest_flow_i %>%
  finalize_workflow(select_best(forest_fitted, metric = "accuracy")) %>%
  fit(data = train2_election_data)
# Choosing the best model
best_rf = best_rf_flow %>% extract_fit_parsnip()
# Plotting the tree
best_rf$fit %>% rpart.plot()
```

```{r}
test2_election_data$i_rep_2016_ind = is.factor(test2_election_data$i_rep_2016_ind)

rpart.plot(rf)
```

# Part 4: Boosting
```{r boosting w/ state, warning=FALSE}
p_load(gbm,caret)

train_boosting = train_election_data %>% 
  select(-c("county","pred_prob","i_rep_2016_ind")) %>%
  mutate(state = as.factor(state),
         i_republican_2016  = as.factor(i_republican_2016))
test_boosting = test_election_data %>% 
  select(-c("county","pred_prob","i_rep_2016_ind")) %>%
  mutate(state = as.factor(state),
         i_republican_2016  = as.factor(i_republican_2016))

model_gbm = gbm(i_republican_2016~.,
                data = train_boosting,
                distribution = 'multinomial',
                cv.folds = 10,
                shrinkage = 0.01,
                n.minobsinnode = 2,
                n.trees = 100)
summary(model_gbm)


test_boosting$boosting_pred = predict.gbm(object = model_gbm,
                   newdata = test_boosting,
                   n.trees = 100,           
                   type = "response")
```

```{r boosting w/o state, warning=FALSE}
train_boosting2 = train_boosting %>% 
  select(-c("state")) 
test_boosting2 = test_boosting %>% 
  select(-c("state"))

model_gbm2 = gbm(i_republican_2016~.,
                data = train_boosting2,
                distribution = 'multinomial',
                cv.folds = 10,
                shrinkage = 0.01,
                n.minobsinnode = 2,
                n.trees = 100)
summary(model_gbm2)
test_boosting$boosting_pred2 = predict.gbm(object = model_gbm2,
                   newdata = test_boosting2,
                   n.trees = 100,           
                   type = "response")
```
# Part 5: Reflection